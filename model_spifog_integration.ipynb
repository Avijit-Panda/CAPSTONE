{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Avijit-Panda/CAPSTONE/blob/learning-algos-come-here/model_spifog_integration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C_Iq_URAd8w3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mne"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fLtnEOZBY330",
        "outputId": "05d56538-0c21-448c-e181-fb4df07ddf3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mne\n",
            "  Downloading mne-1.5.1-py3-none-any.whl (7.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.10/dist-packages (from mne) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from mne) (1.11.3)\n",
            "Requirement already satisfied: matplotlib>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from mne) (3.7.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from mne) (4.66.1)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.10/dist-packages (from mne) (1.7.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from mne) (4.4.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mne) (23.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from mne) (3.1.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4.0->mne) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4.0->mne) (0.12.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4.0->mne) (4.43.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4.0->mne) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4.0->mne) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4.0->mne) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4.0->mne) (2.8.2)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.5->mne) (3.11.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.5->mne) (2.31.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->mne) (2.1.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.4.0->mne) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2023.7.22)\n",
            "Installing collected packages: mne\n",
            "Successfully installed mne-1.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "tL2nvwX4Y87y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sfreq=128\n"
      ],
      "metadata": {
        "id": "1ENwyRTkgzSu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.io import loadmat\n",
        "import mne\n",
        "data=loadmat(\"/content/drive/MyDrive/dataset/ADHD_part1/v3p.mat\")\n",
        "eeg_data = data['v3p']\n",
        "#we transpose as we require the data to be in the form of (num_channels,num_samles)\n",
        "eeg_data=eeg_data.transpose()\n",
        "eeg_data.shape\n",
        "ch_names = ['Fz', 'Cz', 'Pz', 'C3', 'T3', 'C4', 'T4', 'Fp1', 'Fp2', 'F3', 'F4', 'F7', 'F8', 'P3', 'P4', 'T5', 'T6', 'O1', 'O2']  # List of channel names\n",
        "sfreq = 128  # Sampling frequency also provided in dataset\n",
        "\n",
        "# Create MNE info structure\n",
        "info = mne.create_info(ch_names=ch_names, sfreq=sfreq, ch_types='eeg')\n",
        "\n",
        "# Create MNE Raw object\n",
        "raw = mne.io.RawArray(data=eeg_data, info=info)"
      ],
      "metadata": {
        "id": "2dW-GR1DZZmM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from glob import glob\n",
        "import os\n",
        "import mne\n",
        "import numpy as np\n",
        "import pandas\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "YjfyVl9_dDua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "patient_file_path=glob(\"/content/drive/MyDrive/dataset/ADHD_part1/*.mat\")\n",
        "control_file_path=glob(\"/content/drive/MyDrive/dataset/Control_part1/*.mat\")\n",
        "print(len(patient_file_path))\n",
        "print((len(control_file_path)))"
      ],
      "metadata": {
        "id": "9lJR9f9ydSX5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_data(file_path):\n",
        "  data=mne.io.read_raw_edf(file_path,preload=True)\n",
        "  data.set_eeg_reference()\n",
        "  data.filter(l_freq=2,h_freq=30,fir_design=\"firwin\")\n",
        "  ica = mne.preprocessing.ICA(n_components=19, random_state=69,method='fastica')#n_components shouldnt be more htan the no of labels so for trial ill use 19\n",
        "  ica.fit(data)\n",
        "  theta_band = (4, 8)   # Theta band (4-8 Hz)\n",
        "  beta_band = (13, 30)  # Beta band (13-30 Hz)\n",
        "\n",
        "  # Compute the power spectral density (PSD) for each IC\n",
        "  psd = ica.get_sources(data, start=0, stop=data.times[-1]).get_data()\n",
        "  psd = np.abs(np.fft.fft(psd))**2\n",
        "\n",
        "    # Define frequency values and indices within the theta and beta bands\n",
        "  freqs = np.fft.fftfreq(data.n_times, d=1/data.info['sfreq'])\n",
        "  theta_indices = np.where((freqs >= theta_band[0]) & (freqs <= theta_band[1]))[0]\n",
        "  beta_indices = np.where((freqs >= beta_band[0]) & (freqs <= beta_band[1]))[0]\n",
        "  theta_metrics = np.mean(psd[:, theta_indices], axis=1)\n",
        "  beta_metrics = np.mean(psd[:, beta_indices], axis=1)\n",
        "  theta_std=np.std(psd[:,theta_indices],axis=1)\n",
        "  beta_std=np.std(psd[:,beta_indices],axis=1)\n",
        "  threshold_multiplier=2#statistical analysis, larger than this mustbe artifacts\n",
        "  theta_threshold = threshold_multiplier*theta_std\n",
        "  beta_threshold = threshold_multiplier*beta_std\n",
        "  theta_artifact_ICs = np.where(theta_metrics > theta_threshold)[0]\n",
        "  beta_artifact_ICs = np.where(beta_metrics > beta_threshold)[0]\n",
        "\n",
        "  artifact_ICs = np.union1d(theta_artifact_ICs, beta_artifact_ICs)\n",
        "\n",
        "  ica.exclude = artifact_ICs\n",
        "\n",
        "\n",
        "  cleaned_data = data.copy()\n",
        "  ica.apply(cleaned_data)\n",
        "  epochs=mne.make_fixed_length_epochs(cleaned_data,duration=3,overlap=1)\n",
        "  array=epochs.get_data()\n",
        "  return array"
      ],
      "metadata": {
        "id": "m5SFAqrZd4Ac"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "#reading from control and adhd files\n",
        "control_epoch_array=[read_data(i) for i in control_file_path]\n",
        "patient_epoch_array=[read_data(i) for i in patient_file_path]"
      ],
      "metadata": {
        "id": "W6hnRBCnebMT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "control_epoch_labels=[len(i)*[0] for i in control_epoch_array]\n",
        "patient_epoch_labels=[len(i)*[1] for i in patient_epoch_array]\n",
        "len(control_epoch_labels),len(patient_epoch_labels)"
      ],
      "metadata": {
        "id": "xopowv5Te0sr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_list=control_epoch_array+patient_epoch_array\n",
        "label_list=control_epoch_labels+patient_epoch_labels"
      ],
      "metadata": {
        "id": "IKH8wRsLe_x4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "group_list=[[i]*len(j) for i,j in enumerate(data_list)]"
      ],
      "metadata": {
        "id": "VcWSi_zsfBGR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# vstack() is used to stack or concate the sequence of given arrays vertically(row-wise).\n",
        "data_array=np.vstack(data_list)\n",
        "# hstack() stacks arrays in sequence horizontally (column wise)\n",
        "label_array=np.hstack(label_list)\n",
        "group_array=np.hstack(group_list)\n",
        "print(data_array.shape,label_array.shape,group_array.shape)"
      ],
      "metadata": {
        "id": "sQBzXJHufLC5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.io\n",
        "import mne\n",
        "\n",
        "def read_data(file_path):\n",
        "    # Load .mat file\n",
        "    mat_data = scipy.io.loadmat(file_path)\n",
        "\n",
        "    # Extract EEG data\n",
        "    eeg_data = mat_data[(file_path.split(\"/\")[-1]).split(\".\")[0]]\n",
        "    eeg_data=eeg_data.transpose()\n",
        "\n",
        "    # Define channel names\n",
        "    ch_names = ['Fz', 'Cz', 'Pz', 'C3', 'T3', 'C4', 'T4', 'Fp1', 'Fp2', 'F3', 'F4', 'F7', 'F8', 'P3', 'P4', 'T5', 'T6', 'O1', 'O2']\n",
        "    # Define sampling frequency\n",
        "    sfreq = 128\n",
        "    # Create MNE info structure\n",
        "    info = mne.create_info(ch_names=ch_names, sfreq=sfreq, ch_types='eeg')\n",
        "    # Create MNE Raw object\n",
        "    raw = mne.io.RawArray(data=eeg_data, info=info)\n",
        "    # Set EEG reference\n",
        "    # now trying with average\n",
        "    raw.set_eeg_reference(ref_channels='average')\n",
        "    # Apply bandpass filter\n",
        "    # Delta (0.5 - 4 Hz): Associated with deep sleep and certain cognitive processes.\n",
        "    # Theta (4 - 8 Hz): Related to memory processes, attention, and some meditative states.\n",
        "    # Alpha (8 - 13 Hz): Most prominent in relaxed states with eyes closed, often related to a resting state or mental relaxation.\n",
        "    # Beta (13 - 30 Hz): Associated with active cognitive processing, alertness, and concentration.\n",
        "    # Gamma (30 - 100 Hz): Often observed during complex cognitive tasks and sensory integration.\n",
        "    raw.filter(l_freq=4, h_freq=12)\n",
        "    # Create fixed-length epochs\n",
        "    duration = 5  # Epoch duration in seconds\n",
        "    overlap = 0.5  # Epoch overlap in seconds\n",
        "    #events = mne.make_fixed_length_events(raw, duration=duration, overlap=1)\n",
        "    #epochs = mne.Epochs(raw, events, tmin=0, tmax=duration, baseline=None, preload=True)\n",
        "    # an epoch refers to a segment of continuous EEG data that is extracted based on specific criteria, such as a fixed duration or the occurrence of an event. It is a way to divide the continuous EEG signal into smaller, temporally discrete segments for analysis.\n",
        "    epochs=mne.make_fixed_length_epochs(raw,duration=5,overlap=overlap)\n",
        "    array=epochs.get_data()\n",
        "    # Get data array from epochs\n",
        "    array = epochs.get_data()\n",
        "    return array\n"
      ],
      "metadata": {
        "id": "7KOTBtWbd_eh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install snntorch"
      ],
      "metadata": {
        "id": "2GHrD7u_e2WO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import snntorch as snn\n"
      ],
      "metadata": {
        "id": "YDp6K9VWffF5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LIFNeuron(nn.Module):\n",
        "    def __init__(self, dt):\n",
        "        super(LIFNeuron, self).__init__()\n",
        "        self.dt = dt\n",
        "        self.tau_m = 20.0  # Membrane time constant\n",
        "        self.v_reset = 0.0  # Reset potential\n",
        "        self.v_threshold = 1.0  # Spike threshold\n",
        "        self.refractory_period = 5.0  # Refractory period\n",
        "\n",
        "        # Neuron state variables\n",
        "        self.v = self.register_buffer(\"v\", torch.zeros(1))\n",
        "        self.refractory = self.register_buffer(\"refractory\", torch.zeros(1))\n",
        "\n",
        "    def forward(self, I):\n",
        "        if not self.refractory:\n",
        "            self.v += (-self.v + I * self.tau_m) * self.dt / self.tau_m\n",
        "\n",
        "            if self.v >= self.v_threshold:\n",
        "                self.v = self.v_reset\n",
        "                self.refractory = self.refractory_period\n",
        "                return torch.tensor(1.0)\n",
        "        else:\n",
        "            self.refractory -= self.dt\n",
        "\n",
        "        return torch.tensor(0.0)\n",
        "\n",
        "# Define the SNN model with LIF neurons\n",
        "class LIFModel(nn.Module):\n",
        "    def __init__(self, dt):\n",
        "        super(LIFModel, self).__init__()\n",
        "\n",
        "        self.lif1 = LIFNeuron(dt=dt)\n",
        "        self.lif2 = LIFNeuron(dt=dt)\n",
        "\n",
        "    def forward(self, x):\n",
        "        spike1 = self.lif1(x)\n",
        "        spike2 = self.lif2(spike1)\n",
        "        return spike2"
      ],
      "metadata": {
        "id": "bP23PtlgfFjc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import copy"
      ],
      "metadata": {
        "id": "5aelkmUroVrK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SpiFoGLearning:\n",
        "    def __init__(self, population_size, generations, elite_fraction, dt):\n",
        "        self.population_size = population_size\n",
        "        self.generations = generations\n",
        "        self.elite_fraction = elite_fraction\n",
        "        self.dt = dt\n",
        "        self.population = self.initialize_population()\n",
        "\n",
        "    def initialize_population(self):\n",
        "        population = []\n",
        "        for _ in range(self.population_size):\n",
        "            lif_model = LIFModel(dt=self.dt)\n",
        "            population.append(lif_model)\n",
        "        return population\n",
        "\n",
        "    def calculate_fitness(actual_spike_times, desired_spike_times):\n",
        "      squared_errors = (actual_spike_times - desired_spike_times)**2\n",
        "      mean_squared_error = np.mean(squared_errors)\n",
        "      return mean_squared_error\n",
        "\n",
        "\n",
        "    def crossover(parent1, parent2):\n",
        "        child = copy.deepcopy(parent1)\n",
        "        crossover_point = np.random.randint(0, len(child.synaptic_weights))\n",
        "\n",
        "        # go9ing to do crossover of synaptic weights and delays\n",
        "        child.synaptic_weights[crossover_point:] = parent2.synaptic_weights[crossover_point:]\n",
        "        child.synaptic_delays[crossover_point:] = parent2.synaptic_delays[crossover_point:]\n",
        "\n",
        "        return child\n",
        "    def mutate(snn):\n",
        "        mutated_snn = copy.deepcopy(snn)\n",
        "        mutation_rate = 0.1\n",
        "\n",
        "        # do for i mutation to synaptic weights and delays\n",
        "        for i in range(len(mutated_snn.synaptic_weights)):\n",
        "            if np.random.rand() < mutation_rate:\n",
        "                mutated_snn.synaptic_weights[i] = np.random.uniform(-1, 1)\n",
        "                mutated_snn.synaptic_delays[i] = np.random.uniform(0, 10)\n",
        "\n",
        "        return mutated_snn\n",
        "\n",
        "\n",
        "    def select_elite_population(self):\n",
        "        fitness_scores = [self.calculate_fitness(model) for model in self.population]\n",
        "        elite_indices = torch.argsort(fitness_scores)[-int(self.elite_fraction * len(self.population)):]\n",
        "        elite_population = [self.population[i] for i in elite_indices]\n",
        "        return elite_population\n",
        "\n",
        "\n",
        "\n",
        "    def spifog_learning(self, input_data, desired_spike_times):\n",
        "        for generation in range(self.generations):\n",
        "            elite_population = self.select_elite_population()\n",
        "\n",
        "            new_population = []\n",
        "            while len(new_population) < self.population_size:\n",
        "                parent1 = torch.random.choice(elite_population)\n",
        "                parent2 = torch.random.choice(elite_population)\n",
        "                child = self.crossover(parent1, parent2)\n",
        "                mutated_child = self.mutate(child)\n",
        "                new_population.append(mutated_child)\n",
        "\n",
        "            self.population = new_population\n",
        "\n",
        "        best_model = self.select_best_model()\n",
        "        return best_model\n",
        "\n",
        "# # Define the LIF neuron model\n",
        "# class LIFNeuron(nn.Module):\n",
        "#     def __init__(self, dt):\n",
        "#         super(LIFNeuron, self).__init__()\n",
        "#         self.dt = dt\n",
        "#         self.tau_m = 20.0  # Membrane time constant\n",
        "#         self.v_reset = 0.0  # Reset potential\n",
        "#         self.v_threshold = 1.0  # Spike threshold\n",
        "#         self.refractory_period = 5.0  # Refractory period\n",
        "\n",
        "#         # Neuron state variables\n",
        "#         self.v = self.register_buffer(\"v\", torch.zeros(1))\n",
        "#         self.refractory = self.register_buffer(\"refractory\", torch.zeros(1))\n",
        "\n",
        "#     def forward(self, I):\n",
        "#         if not self.refractory:\n",
        "#             self.v += (-self.v + I * self.tau_m) * self.dt / self.tau_m\n",
        "\n",
        "#             if self.v >= self.v_threshold:\n",
        "#                 self.v = self.v_reset\n",
        "#                 self.refractory = self.refractory_period\n",
        "#                 return torch.tensor(1.0)\n",
        "#         else:\n",
        "#             self.refractory -= self.dt\n",
        "\n",
        "#         return torch.tensor(0.0)\n",
        "\n",
        "# # Define the SNN model with LIF neurons\n",
        "# class LIFModel(nn.Module):\n",
        "#     def __init__(self, dt):\n",
        "#         super(LIFModel, self).__init__()\n",
        "\n",
        "#         self.lif1 = LIFNeuron(dt=dt)\n",
        "#         self.lif2 = LIFNeuron(dt=dt)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         spike1 = self.lif1(x)\n",
        "#         spike2 = self.lif2(spike1)\n",
        "#         return spike2\n",
        "\n",
        "# # Example usage\n",
        "# if __name__ == \"__main__\":\n",
        "#     dt = 1.0  # Time step (ms)\n",
        "#     spifog = SpiFoGLearning(population_size=50, generations=100, elite_fraction=0.2, dt=dt)\n",
        "#     input_data = torch.tensor([0.2])\n",
        "#     desired_spike_times = torch.tensor([1.0])\n",
        "\n",
        "#     best_model = spifog.spifog_learning(input_data, desired_spike_times)"
      ],
      "metadata": {
        "id": "AdWS4Qg3ej5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import snntorch as snn\n",
        "\n",
        "# Define the model\n",
        "class FeedforwardSNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super().__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "\n",
        "        # Parameters\n",
        "        self.beta = 0.99\n",
        "\n",
        "        # Layers\n",
        "        self.fc1 = nn.Linear(self.input_size, self.hidden_size)\n",
        "        self.lif1 = snn.Leaky(beta=self.beta)\n",
        "        self.fc2 = nn.Linear(self.hidden_size, self.output_size)\n",
        "        self.lif2 = snn.Leaky(beta=self.beta)\n",
        "\n",
        "    def forward(self, x):\n",
        "        mem1 = self.lif1.init_leaky()\n",
        "        mem2 = self.lif2.init_leaky()\n",
        "\n",
        "        spk1, mem1 = self.lif1(self.fc1(x), mem1)\n",
        "        spk2, mem2 = self.lif2(self.fc2(spk1), mem2)\n",
        "\n",
        "        return spk2, mem2"
      ],
      "metadata": {
        "id": "1RCHBppOluLO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dt = 1.0  # Time step (ms)\n",
        "spifog = SpiFoGLearning(population_size=50, generations=100, elite_fraction=0.2, dt=dt)\n",
        "input_data = torch.tensor([0.2])\n",
        "desired_spike_times = torch.tensor([1.0])\n",
        "best_model = spifog.spifog_learning(input_data, desired_spike_times)"
      ],
      "metadata": {
        "id": "xybCGAH5THny"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gr34cd92Y06M"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}